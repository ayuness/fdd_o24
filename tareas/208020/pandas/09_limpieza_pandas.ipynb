{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion de Default en Prestamos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto utilizaremos un sample de los datos de Lending Club. La idea es predecir si cierto usuario cometera Default basado en informacion que la plataforma recolecta. Esto nos ayudara a mejorar la metodologia/pipeline de prestamo.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Contiene los prestamos de esta plataforma:\n",
    "\n",
    "    periodo 2007-2017Q3.\n",
    "    887mil observaciones, sample de 100mil\n",
    "    150 variables\n",
    "    Target: loan status\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un ETL y un EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Limpia los datos de tal manera que al final del ETL queden en formato `tidy`.\n",
    "1. Asegurate de cargar y leer los datos\n",
    "2. Crea una tabla donde se guarde el nombre de la columna y el tipo de dato: (`column_name`,   `type`).\n",
    "3. Asegurate de pensar cual es el tipo de dato correcto. Porque elejiste strig/object o float o int?. No hay respuestas incorrectas como tal, pero tienes que justificar tu decision.\n",
    "4. Maneja missings o nans de la manera adecuada. Justifica cada decision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Preparar lo datos para un pipeline de datos\n",
    "1. Quitar columnas inservibles \n",
    "2. Imputar valores\n",
    "3. Mantener replicabildiad y reproducibilidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No olvides anotar tus justificaciones en celdas para recordar cuando te toque explicarlo.** Puedes agregar el numero de celdas que necesites para poner tu explicacion y el codigo, solo manten la estructura."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vas a obtener 2 errores, solucionalo con los visto en clase.  \n",
    "Tip: Se arreglan con argumentos adicionales de la funcion `read_csv`  \n",
    "Documentacion: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo así me dejó correr el código. También tuve que hacer pip install de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/249270875.py:8: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  loans = pd.read_csv(io.BytesIO(response.content), compression='gzip', encoding_errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
      "0           0  38098114        NaN    15000.0      15000.0          15000.0   \n",
      "1           1  36805548        NaN    10400.0      10400.0          10400.0   \n",
      "2           2  37842129        NaN    21425.0      21425.0          21425.0   \n",
      "3           3  37612354        NaN    12800.0      12800.0          12800.0   \n",
      "4           4  37662224        NaN     7650.0       7650.0           7650.0   \n",
      "\n",
      "         term  int_rate  installment grade  ...  \\\n",
      "0   60 months     12.39       336.64     C  ...   \n",
      "1   36 months      6.99       321.08     A  ...   \n",
      "2   60 months     15.59       516.36     D  ...   \n",
      "3   60 months     17.14       319.08     D  ...   \n",
      "4   36 months     13.66       260.20     C  ...   \n",
      "\n",
      "  hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
      "0                            NaN                          NaN   \n",
      "1                            NaN                          NaN   \n",
      "2                            NaN                          NaN   \n",
      "3                            NaN                          NaN   \n",
      "4                            NaN                          NaN   \n",
      "\n",
      "  disbursement_method debt_settlement_flag  debt_settlement_flag_date  \\\n",
      "0                Cash                    N                        NaN   \n",
      "1                Cash                    N                        NaN   \n",
      "2                Cash                    N                        NaN   \n",
      "3                Cash                    N                        NaN   \n",
      "4                Cash                    N                        NaN   \n",
      "\n",
      "  settlement_status settlement_date settlement_amount settlement_percentage  \\\n",
      "0               NaN             NaN               NaN                   NaN   \n",
      "1               NaN             NaN               NaN                   NaN   \n",
      "2               NaN             NaN               NaN                   NaN   \n",
      "3               NaN             NaN               NaN                   NaN   \n",
      "4               NaN             NaN               NaN                   NaN   \n",
      "\n",
      "  settlement_term  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/sonder-art/fdd_prim_2023/blob/main/codigo/pandas/LoansData_sample.csv.gz?raw=true'\n",
    "\n",
    "# Descargar el archivo\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Verifica errores de conexión\n",
    "\n",
    "# Cargar el contenido descargado directamente en pandas\n",
    "loans = pd.read_csv(io.BytesIO(response.content), compression='gzip', encoding_errors='ignore')\n",
    "\n",
    "print(loans.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla (column_name, type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisa el metodo pd.DataFrame.dtypes. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "id                         int64\n",
       "member_id                float64\n",
       "loan_amnt                float64\n",
       "funded_amnt              float64\n",
       "                          ...   \n",
       "settlement_status         object\n",
       "settlement_date           object\n",
       "settlement_amount        float64\n",
       "settlement_percentage    float64\n",
       "settlement_term          float64\n",
       "Length: 151, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types =loans.dtypes\n",
    "column_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar descripcion de columnas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tabla tiene una descripcion del significado de cada columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuve que hacer pip instal openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                feature                                        description\n",
      "0        acc_now_delinq  The number of accounts on which the borrower i...\n",
      "1  acc_open_past_24mths         Number of trades opened in past 24 months.\n",
      "2            addr_state  The state provided by the borrower in the loan...\n",
      "3              all_util              Balance to credit limit on all trades\n",
      "4            annual_inc  The self-reported annual income provided by th...\n"
     ]
    }
   ],
   "source": [
    "url = 'https://resources.lendingclub.com/LCDataDictionary.xlsx'\n",
    "\n",
    "# Descargar el archivo con requests\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Asegúrate de que la descarga fue exitosa\n",
    "\n",
    "# Leer el archivo descargado con pandas\n",
    "datos_dict = pd.read_excel(io.BytesIO(response.content), engine='openpyxl')\n",
    "datos_dict.columns = ['feature', 'description']\n",
    "\n",
    "print(datos_dict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>The number of accounts on which the borrower i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_open_past_24mths</td>\n",
       "      <td>Number of trades opened in past 24 months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>The state provided by the borrower in the loan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_util</td>\n",
       "      <td>Balance to credit limit on all trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>The self-reported annual income provided by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>settlement_amount</td>\n",
       "      <td>The loan amount that the borrower has agreed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>settlement_percentage</td>\n",
       "      <td>The settlement amount as a percentage of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>settlement_term</td>\n",
       "      <td>The number of months that the borrower will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>* Employer Title replaces Employer Name for al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature                                        description\n",
       "0           acc_now_delinq  The number of accounts on which the borrower i...\n",
       "1     acc_open_past_24mths         Number of trades opened in past 24 months.\n",
       "2               addr_state  The state provided by the borrower in the loan...\n",
       "3                 all_util              Balance to credit limit on all trades\n",
       "4               annual_inc  The self-reported annual income provided by th...\n",
       "..                     ...                                                ...\n",
       "148      settlement_amount  The loan amount that the borrower has agreed t...\n",
       "149  settlement_percentage  The settlement amount as a percentage of the p...\n",
       "150        settlement_term  The number of months that the borrower will be...\n",
       "151                    NaN                                                NaN\n",
       "152                    NaN  * Employer Title replaces Employer Name for al...\n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganizar las entradas para que estén en el mismo orden que el loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   feature                                        description\n",
      "0               Unnamed: 0                                                NaN\n",
      "1                       id      A unique LC assigned ID for the loan listing.\n",
      "2                member_id   A unique LC assigned Id for the borrower member.\n",
      "3                loan_amnt  The listed amount of the loan applied for by t...\n",
      "4              funded_amnt  The total amount committed to that loan at tha...\n",
      "..                     ...                                                ...\n",
      "146      settlement_status  The status of the borrower’s settlement plan. ...\n",
      "147        settlement_date  The date that the borrower agrees to the settl...\n",
      "148      settlement_amount  The loan amount that the borrower has agreed t...\n",
      "149  settlement_percentage  The settlement amount as a percentage of the p...\n",
      "150        settlement_term  The number of months that the borrower will be...\n",
      "\n",
      "[151 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'loans' is your DataFrame\n",
    "loans_columns = loans.columns.tolist()  # Get the list of columns from the loans DataFrame\n",
    "\n",
    "# Reorder datos_dict based on the columns in loans\n",
    "# We will filter out features that are not in loans_columns\n",
    "ordered_dict = datos_dict[datos_dict['feature'].isin(loans_columns)].copy()\n",
    "ordered_dict = ordered_dict.set_index('feature').reindex(loans_columns).reset_index()\n",
    "\n",
    "# Display the ordered table\n",
    "print(ordered_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** el DataFrame de `datos_dict` creada en las celdas anteriores en formato **pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo guardar\n",
    "datos_dict.to_pickle('ordered_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo para cargar\n",
    "datos_dict_loaded = pd.read_pickle('ordered_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza las transformaciones o casteos (casting) que creas necesarios a tus datos de tal manera que el typo de dato sea adecuado. Al terminar recrea la tabla `column_types` con los nuevos tipos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No olvides anotar tus justificaciones para recordar cuando te toque explicarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los tipos de datos\n",
    "category abarca menos memoria\n",
    "Int64 permite NAN\n",
    "dates para fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/2347453219.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  loans[col] = pd.to_datetime(loans[col], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                        int64\n",
      "id                                int64\n",
      "member_id                         Int64\n",
      "loan_amnt                       float64\n",
      "funded_amnt                     float64\n",
      "                              ...      \n",
      "settlement_status                object\n",
      "settlement_date          datetime64[ns]\n",
      "settlement_amount               float64\n",
      "settlement_percentage           float64\n",
      "settlement_term                 float64\n",
      "Length: 151, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ajustar tipos de datos\n",
    "loans = loans.astype({\n",
    "    'member_id': 'Int64',  # Identificador con valores nulos\n",
    "    'term': 'category',\n",
    "    'grade': 'category',\n",
    "    'sub_grade': 'category',\n",
    "    'home_ownership': 'category',\n",
    "    'verification_status': 'category',\n",
    "    'loan_status': 'category',\n",
    "    'pymnt_plan': 'category',\n",
    "    'zip_code': 'object',\n",
    "    'addr_state': 'category',\n",
    "    'hardship_flag': 'bool',\n",
    "    'debt_settlement_flag': 'bool'\n",
    "})\n",
    "\n",
    "# Convertir columnas de fechas\n",
    "date_columns = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', \n",
    "                'last_credit_pull_d', 'hardship_start_date', 'hardship_end_date', \n",
    "                'payment_plan_start_date', 'debt_settlement_flag_date', 'settlement_date']\n",
    "for col in date_columns:\n",
    "    loans[col] = pd.to_datetime(loans[col], errors='coerce')\n",
    "\n",
    "# Mostrar los nuevos tipos de datos\n",
    "column_types = loans.dtypes\n",
    "print(column_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/3476301222.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  loans['emp_length'] = loans['emp_length'].replace(length_mapping)\n",
      "/var/folders/t7/x59wmtvn5zz3dylxlv_fcch80000gn/T/ipykernel_23479/3476301222.py:27: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  loans['home_ownership'] = loans['home_ownership'].replace('ANY', 'OTHER')\n"
     ]
    }
   ],
   "source": [
    "# Manejo seguro de 'Unnamed: 0'\n",
    "if 'Unnamed: 0' in loans.columns:\n",
    "    loans = loans.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# emp_title\n",
    "loans['emp_title'] = loans['emp_title'].astype(str)\n",
    "\n",
    "# emp_length\n",
    "unique_titles = loans['emp_length'].unique()\n",
    "length_mapping = {\n",
    "    '10+ years': 10,\n",
    "    '< 1 year': 0,\n",
    "    '1 year': 1,\n",
    "    '2 years': 2,\n",
    "    '3 years': 3,\n",
    "    '4 years': 4,\n",
    "    '5 years': 5,\n",
    "    '6 years': 6,\n",
    "    '7 years': 7,\n",
    "    '8 years': 8,\n",
    "    '9 years': 9\n",
    "}\n",
    "loans['emp_length'] = loans['emp_length'].replace(length_mapping)\n",
    "loans['emp_length'] = loans['emp_length'].astype('Int64')  # Permite valores NaN\n",
    "\n",
    "# home_ownership\n",
    "loans['home_ownership'] = loans['home_ownership'].replace('ANY', 'OTHER')\n",
    "loans['home_ownership'] = loans['home_ownership'].astype('category')\n",
    "\n",
    "# disbursement_method\n",
    "loans['disbursement_method'] = loans['disbursement_method'].astype('category')\n",
    "\n",
    "# debt_settlement_flag\n",
    "loans['debt_settlement_flag'] = loans['debt_settlement_flag'].map({'Y': True, 'N': False})\n",
    "\n",
    "# debt_settlement_flag_date\n",
    "loans['debt_settlement_flag_date'] = pd.to_datetime(\n",
    "    loans['debt_settlement_flag_date'], format='%b-%Y', errors='coerce')\n",
    "\n",
    "# settlement_status\n",
    "loans['settlement_status'] = loans['settlement_status'].astype('category')\n",
    "\n",
    "# settlement_date\n",
    "loans['settlement_date'] = pd.to_datetime(\n",
    "    loans['settlement_date'], format='%b-%Y', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                int64\n",
       "member_id                         Int64\n",
       "loan_amnt                       float64\n",
       "funded_amnt                     float64\n",
       "funded_amnt_inv                 float64\n",
       "                              ...      \n",
       "settlement_status              category\n",
       "settlement_date          datetime64[ns]\n",
       "settlement_amount               float64\n",
       "settlement_percentage           float64\n",
       "settlement_term                 float64\n",
       "Length: 150, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_types =loans.dtypes\n",
    "column_types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de NaNs o missings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maneja los datos de tipos missing. Elije una estrategia adecuada dependiendo del tipo de dato que le asignaste a la columna.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea codigo para **guardar** y **cargar** un archivo JSON en el que se guarde la `estrategia` y `valor` que utilizaste para **imputar**. Por ejemplo: Si hay una columna que se llama `columna 3` y utilizaste la estrategia de imputacion de media, y existe otra llamada `columna 4` y  elegiste la palabra 'missing' el JSON debera contener:  \n",
    "  \n",
    " `{'columna 3':{'estrategia':'mean', 'valor':3.4}, 'columna 4':{'estrategia':'identificador', 'valor':'missing'}}`  \n",
    "\n",
    " De tal manera que para cada columna que tenga un metodo de imputacion apunte a otro diccionario donde el **key** `estrategia` describa de manera sencilla el metodo, y el **key** `valor` el valor usado. En general:   \n",
    " `{'nombre de la columna':{'estrategia':'descripcion de estrategia', 'valor':'valor utilizado'}}`. \n",
    " \n",
    "\n",
    "De utilizar mas de un metodo puedes anidarlos en una lista  \n",
    "  `[{...},{...}]`.  \n",
    "\n",
    "Incluso si la columna utilizada no sufrio imputacion, es necesario que la agregues al JSON.\n",
    "\n",
    "La idea es que cualquier otra persona pueda cargar el el archivo JSON con tu funcion, entender que hiciste y replicarlo facilmente. No existe solo una respuesta correcta, pero tendras que justificar y explicar tus deciciones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para manejar imputación categórica\n",
    "def imputar_categoricas_a_missing(loans, categorias_a_missing):\n",
    "    print(\"Imputando categóricas con 'MISSING'...\")\n",
    "    for column in categorias_a_missing:\n",
    "        if column in loans.columns:\n",
    "            if pd.api.types.is_categorical_dtype(loans[column]):\n",
    "                if 'MISSING' not in loans[column].cat.categories:\n",
    "                    loans[column] = loans[column].cat.add_categories(['MISSING'])\n",
    "            loans[column] = loans[column].fillna('MISSING')\n",
    "            print(f\"Columna {column} imputada con 'MISSING'.\")\n",
    "        else:\n",
    "            print(f\"Columna {column} no encontrada en el DataFrame.\")\n",
    "\n",
    "# Función para imputar con -1\n",
    "def imputar_a_menos1(loans, amenos1):\n",
    "    print(\"Imputando con -1...\")\n",
    "    for col in amenos1:\n",
    "        if col in loans.columns:\n",
    "            loans[col] = loans[col].fillna(-1)\n",
    "            print(f\"Columna {col} imputada con -1.\")\n",
    "        else:\n",
    "            print(f\"Columna {col} no encontrada en el DataFrame.\")\n",
    "\n",
    "# Función para imputar con medianas y condiciones\n",
    "def imputar_mediana_condicional(loans, columnas_condicionales, condiciones):\n",
    "    print(\"Imputando con mediana condicional...\")\n",
    "    for col, (condicion_col, valor_condicion) in columnas_condicionales.items():\n",
    "        if col in loans.columns:\n",
    "            mediana = loans[loans[col].notna()][col].median()\n",
    "            loans[col] = loans.apply(\n",
    "                lambda row: valor_condicion if row[condicion_col] == 0 \n",
    "                else mediana if pd.isna(row[col]) \n",
    "                else row[col],\n",
    "                axis=1\n",
    "            )\n",
    "            print(f\"Columna {col} imputada con mediana condicional.\")\n",
    "        else:\n",
    "            print(f\"Columna {col} no encontrada en el DataFrame.\")\n",
    "\n",
    "# Función para imputar fechas con placeholder\n",
    "def imputar_fechas_placeholder(loans, columnas_fecha, placeholder_date):\n",
    "    print(\"Imputando fechas con placeholder...\")\n",
    "    for col in columnas_fecha:\n",
    "        if col in loans.columns:\n",
    "            loans[col] = loans[col].fillna(placeholder_date)\n",
    "            print(f\"Columna {col} imputada con fecha placeholder.\")\n",
    "        else:\n",
    "            print(f\"Columna {col} no encontrada en el DataFrame.\")\n",
    "\n",
    "# Función para imputar con 0\n",
    "def imputar_a_cero(loans, columnas_a_cero):\n",
    "    print(\"Imputando con 0...\")\n",
    "    for col in columnas_a_cero:\n",
    "        if col in loans.columns:\n",
    "            loans[col] = loans[col].fillna(0)\n",
    "            print(f\"Columna {col} imputada con 0.\")\n",
    "        else:\n",
    "            print(f\"Columna {col} no encontrada en el DataFrame.\")\n",
    "\n",
    "# Función principal\n",
    "def imputacion_loans(loans):\n",
    "    print(\"Iniciando imputación...\")\n",
    "    \n",
    "    # Columnas categóricas a imputar con 'MISSING'\n",
    "    categorias_a_missing = ['hardship_type', 'hardship_reason', 'hardship_status', 'hardship_loan_status', 'settlement_status']\n",
    "    imputar_categoricas_a_missing(loans, categorias_a_missing)\n",
    "\n",
    "    # Columnas a imputar con -1\n",
    "    amenos1 = ['emp_length', 'mths_since_last_delinq', 'mths_since_last_record', 'mths_since_last_major_derog', \n",
    "               'mo_sin_old_il_acct', 'mths_since_recent_bc', 'mths_since_recent_bc_dlq', \n",
    "               'mths_since_recent_inq', 'mths_since_recent_revol_delinq']\n",
    "    imputar_a_menos1(loans, amenos1)\n",
    "\n",
    "    # Columnas a imputar con medianas condicionales\n",
    "    columnas_condicionales = {\n",
    "        'revol_util': ('revol_bal', 0),\n",
    "        'bc_util': ('bc_open_to_buy', 0)\n",
    "    }\n",
    "    imputar_mediana_condicional(loans, columnas_condicionales)\n",
    "\n",
    "    # Columnas de fechas a imputar con un placeholder\n",
    "    columnas_fecha = ['hardship_start_date', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d', \n",
    "                      'hardship_end_date', 'payment_plan_start_date', 'debt_settlement_flag_date', \n",
    "                      'settlement_date']\n",
    "    imputar_fechas_placeholder(loans, columnas_fecha, pd.Timestamp('1900-01-01'))\n",
    "\n",
    "    # Columnas a imputar con 0\n",
    "    columnas_a_cero = ['bc_open_to_buy', 'num_tl_120dpd_2m', 'percent_bc_gt_75', 'deferral_term',\n",
    "                        'hardship_amount', 'hardship_length', 'hardship_dpd', \n",
    "                        'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', \n",
    "                        'hardship_last_payment_amount', 'settlement_amount', 'settlement_percentage', \n",
    "                        'settlement_term']\n",
    "    imputar_a_cero(loans, columnas_a_cero)\n",
    "\n",
    "    # Detectar columnas completamente nulas y eliminarlas\n",
    "    columnas_completamente_nulas = [col for col in loans.columns if loans[col].isna().all()]\n",
    "    if columnas_completamente_nulas:\n",
    "        loans.drop(columns=columnas_completamente_nulas, inplace=True)\n",
    "        print(f\"Columnas eliminadas (completamente nulas): {columnas_completamente_nulas}\")\n",
    "    else:\n",
    "        print(\"No hay columnas completamente nulas.\")\n",
    "\n",
    "    # Detectar columnas con valores faltantes restantes\n",
    "    columnas_con_faltantes = [col for col in loans.columns if loans[col].isna().any()]\n",
    "    if columnas_con_faltantes:\n",
    "        print(\"Columnas con valores faltantes restantes:\", columnas_con_faltantes)\n",
    "    else:\n",
    "        print(\"No hay columnas con valores faltantes.\")\n",
    "\n",
    "# Asegúrate de llamar a la función principal con un DataFrame\n",
    "# Ejemplo:\n",
    "# loans = pd.read_csv('ruta_a_tu_archivo.csv')\n",
    "# imputacion_loans(loans)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo para salvar y cargar JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def create_imputation_json(loans, median_values):\n",
    "    \"\"\"\n",
    "    Crea un archivo JSON con las estrategias de imputación aplicadas a las columnas del DataFrame.\n",
    "    \"\"\"\n",
    "    # Diccionario para almacenar la información de imputación\n",
    "    imputation_info = {}\n",
    "\n",
    "    # Columnas eliminadas completamente nulas\n",
    "    columnas_completamente_nulas = [col for col in loans.columns if loans[col].isna().all()]\n",
    "    for column in columnas_completamente_nulas:\n",
    "        imputation_info[column] = {\n",
    "            'estrategia': 'Dropeamos columna - todos valores NaN',\n",
    "            'valor': None\n",
    "        }\n",
    "\n",
    "    # Imputación con -1\n",
    "    amenos1 = ['emp_length', 'mths_since_last_delinq', 'mths_since_last_record', \n",
    "               'mths_since_last_major_derog', 'mo_sin_old_il_acct', 'mths_since_recent_bc', \n",
    "               'mths_since_recent_bc_dlq', 'mths_since_recent_inq', 'mths_since_recent_revol_delinq']\n",
    "    for col in amenos1:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Indicar que no con identificador negativo, un 0 implicaria cosas',\n",
    "            'valor': -1\n",
    "        }\n",
    "\n",
    "    # Imputación con 0\n",
    "    columnas_a_cero = ['bc_open_to_buy', 'num_tl_120dpd_2m', 'percent_bc_gt_75', 'deferral_term',\n",
    "                       'hardship_amount', 'hardship_length', 'hardship_dpd', \n",
    "                       'orig_projected_additional_accrued_interest', 'hardship_payoff_balance_amount', \n",
    "                       'hardship_last_payment_amount', 'settlement_amount', 'settlement_percentage', \n",
    "                       'settlement_term']\n",
    "    for col in columnas_a_cero:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Identificador para decir que es nada',\n",
    "            'valor': 0\n",
    "        }\n",
    "\n",
    "    # Fechas con placeholder\n",
    "    columnas_fecha = ['hardship_start_date', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d', \n",
    "                      'hardship_end_date', 'payment_plan_start_date', 'debt_settlement_flag_date', \n",
    "                      'settlement_date']\n",
    "    for col in columnas_fecha:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Indicador que no hay fecha registrada',\n",
    "            'valor': '1900-01-01'\n",
    "        }\n",
    "\n",
    "    # Imputación condicional con mediana\n",
    "    columnas_condicionales = ['revol_util', 'bc_util']\n",
    "    for i, col in enumerate(columnas_condicionales):\n",
    "        imputation_info[col] = [\n",
    "            {'estrategia': 'median imputation', 'valor': median_values[i]},\n",
    "            {'estrategia': 'identificador', 'valor': 0}\n",
    "        ]\n",
    "\n",
    "    # Categóricas con 'MISSING'\n",
    "    categorias_a_missing = ['hardship_type', 'hardship_reason', 'hardship_status', \n",
    "                             'hardship_loan_status', 'settlement_status']\n",
    "    for col in categorias_a_missing:\n",
    "        imputation_info[col] = {\n",
    "            'estrategia': 'Identificador categorico',\n",
    "            'valor': 'MISSING'\n",
    "        }\n",
    "\n",
    "    # Agregar columnas sin imputación explícita\n",
    "    all_columns = loans.columns.tolist()\n",
    "    for col in all_columns:\n",
    "        if col not in imputation_info:\n",
    "            imputation_info[col] = {\n",
    "                'estrategia': 'no imputation',\n",
    "                'valor': None\n",
    "            }\n",
    "\n",
    "    # Guardar el diccionario como JSON\n",
    "    with open('imputation_strategies.json', 'w') as json_file:\n",
    "        json.dump(imputation_info, json_file, indent=4)\n",
    "    print(\"Archivo 'imputation_strategies.json' guardado correctamente.\")\n",
    "\n",
    "def load_and_print_json(file_path):\n",
    "    \"\"\"\n",
    "    Carga y muestra un archivo JSON con las estrategias de imputación.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            imputation_info = json.load(json_file)\n",
    "        print(json.dumps(imputation_info, indent=4))  # Pretty print\n",
    "    except FileNotFoundError:\n",
    "        print(f\"El archivo {file_path} no existe.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error al decodificar el JSON en el archivo {file_path}.\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# Supongamos que loans es tu DataFrame y median_values contiene las medianas calculadas\n",
    "# loans = pd.read_csv(\"tu_dataset.csv\")\n",
    "# median_values = [10.5, 20.0]  # Ejemplo de valores calculados\n",
    "# create_imputation_json(loans, median_values)\n",
    "# load_and_print_json('imputation_strategies.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
